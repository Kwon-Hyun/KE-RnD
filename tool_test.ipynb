{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f572e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hyunkwon\\robot_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8b6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.9.1+cpu\n",
      "CUDA 사용 가능 여부: False\n"
     ]
    }
   ],
   "source": [
    "## GPU 사용을 위해 확인하는 용도의 코드들\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\") # 버전 이름 뒤에 +cu118이나 +cu121 같은 글자가 없고 숫자만 있다면 CPU 전용 버전이 설치된 것\n",
    "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")  # True가 나와야 GPU 전용 torch로 진행 가능 # False라면 커널 재설정 후 다시 시도\n",
    "\n",
    "# GPU용 pytorch 설치 후 다시 커널 실행해서 확인할 부분\n",
    "print(f\"사용 중인 GPU 이름: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef3169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 사용 중인 장치: cpu\n"
     ]
    }
   ],
   "source": [
    "# 0. 장치 설정 (GPU 최우선, 없으면 CPU)\n",
    "# --- [설정부] ---\n",
    "\n",
    "IMG_DIR = './img'\n",
    "MASK_DIR = './mask'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50\n",
    "LR = 0.0001\n",
    "\n",
    "print(f\"현재 사용 중인 장치: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d7286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [1. 데이터셋 정의] ---\n",
    "class ToolWearDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        # 이미지 파일 리스트 가져오기\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, img_name) # 파일명 동일 가정\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 마스크가 없을 경우를 대비한 예외처리\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = mask / 255.0\n",
    "        else:\n",
    "            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            \n",
    "        return image, mask.float().unsqueeze(0), img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5ee76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1017)' thrown while requesting HEAD https://huggingface.co/smp-hub/mobilenet_v2.imagenet/resolve/e67aa804e17f7b404b629127eabbd224c4e0690b/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "c:\\hyunkwon\\robot_test\\lib\\site-packages\\segmentation_models_pytorch\\encoders\\__init__.py:136: UserWarning: Error loading mobilenet_v2 `imagenet` weights from Hugging Face Hub, trying loading from original url...\n",
      "  warnings.warn(message, UserWarning)\n",
      "C:\\Users\\KWON HYUN\\AppData\\Local\\Temp\\ipykernel_34960\\1350571419.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\hyunkwon\\robot_test\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# --- [2. 변환 및 모델 준비] ---\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation='sigmoid'\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = smp.losses.DiceLoss(mode='binary')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9166d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [3. 학습 함수] ---\n",
    "def train():\n",
    "    dataset = ToolWearDataset(IMG_DIR, MASK_DIR, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    print(f\"학습 시작 장치: {DEVICE}\")\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for imgs, masks, _ in loader:\n",
    "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=(DEVICE.type == 'cuda')):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, masks)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), \"tool_model.pth\")\n",
    "    print(\"모델 저장 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5004a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [4. 결과 확인(추론) 함수] ---\n",
    "def predict_and_show():\n",
    "    model.eval()\n",
    "    test_img_name = os.listdir(IMG_DIR)[0] # 첫 번째 이미지로 테스트\n",
    "    image = cv2.imread(os.path.join(IMG_DIR, test_img_name))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 전처리\n",
    "    h, w = image.shape[:2]\n",
    "    input_img = transform(image=image_rgb)['image'].unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)\n",
    "        # 다시 원래 크기로 복구\n",
    "        pred_mask = torch.nn.functional.interpolate(output, size=(h, w), mode='bilinear')\n",
    "        pred_mask = (pred_mask > 0.5).cpu().numpy().squeeze()\n",
    "    \n",
    "    # 시각화: 원본 위에 마스크를 붉은색으로 덧씌움(Overlay)\n",
    "    overlay = image_rgb.copy()\n",
    "    overlay[pred_mask > 0] = [255, 0, 0] # 마모 부위를 빨간색으로\n",
    "    result = cv2.addWeighted(image_rgb, 0.7, overlay, 0.3, 0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(image_rgb); plt.title(\"Original\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(pred_mask, cmap='gray'); plt.title(\"Predicted Mask\")\n",
    "    plt.subplot(1, 3, 3); plt.imshow(result); plt.title(\"Overlay Result\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8760e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작 장치: cpu\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     predict_and_show()\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m imgs, masks, _ \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     10\u001b[0m         imgs, masks \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(DEVICE), masks\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\hyunkwon\\robot_test\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\hyunkwon\\robot_test\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\hyunkwon\\robot_test\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\hyunkwon\\robot_test\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mToolWearDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_dir, img_name) \u001b[38;5;66;03m# 파일명 동일 가정\u001b[39;00m\n\u001b[0;32m     18\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m---> 19\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 마스크가 없을 경우를 대비한 예외처리\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(mask_path):\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    predict_and_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcb286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
